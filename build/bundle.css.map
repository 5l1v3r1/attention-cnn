{
  "version": 3,
  "file": "bundle.css",
  "sources": [
    "../../src/App.svelte"
  ],
  "sourcesContent": [
    "<script>\n  import _ from \"lodash-es\";\n\n  import Grid from \"./Grid.svelte\";\n\n  let useAttentionContent = true;\n  let withSoftmax = true;\n\n  const contentAttentionTypes = [\n    [\"attention (qr+qk)\", \"attention\"],\n    [\"positional only scores (qr)\", \"q^Tr\"],\n    [\"content only scores (qk)\", \"q^Tk\"]\n  ];\n\n  const positionAttentionDisplays = [\n    [\"positional attention\", \"attention\"],\n  ];\n\n  let selectedContentAttentionType;\n  let selectedPositionAttentionType;\n\n  let selectedColumn = Math.round(numberColumns / 3);\n  let selectedRow = Math.round(numberColumns / 4);\n\n  const onChangeRowColumn = (row, col) => {\n    selectedRow = row;\n    selectedColumn = col;\n  };\n\n  let selectImageContent = \"batch\";\n  let selectImageLocation = \"position\";\n  $: selectedImage = useAttentionContent ? selectImageContent : selectImageLocation;\n\n  const numberColumns = 16;\n  const squareSize = 6;\n\n  const onSelectImage = imageIndex => {\n    if (useAttentionContent) {\n      selectImageContent = imageIndex\n    } else {\n      selectImageLocation = imageIndex\n    }\n  };\n\n  const pairsToDict = listOfPairs => {\n    return _.zipObject(..._.zip(...listOfPairs));\n  };\n\n  $: filename = filenameAt(selectedRow, selectedColumn);\n\n  $: filenameAt = (col, row) => ([\n    \"png\",\n    useAttentionContent ? \"learned_qk_qr\" : \"learned\",\n    (useAttentionContent\n      ? selectedContentAttentionType\n      : selectedPositionAttentionType) + (withSoftmax ? \"_proba\" : \"\"),\n    \"image_\" + selectedImage,\n    \"img_\" + col + \"_\" + row + \".png\"\n  ].join(\"/\"));\n</script>\n\n<style>\n  .sampleImage {\n    margin-right: 12px;\n    margin-bottom: 8px;\n    position: relative;\n    float: left;\n    /* border: 1px solid black; */\n    height: 96px;\n  }\n\n  .selected {\n    box-shadow: 0 0 5px #2980b9;\n    /* border: 3px solid #2980b9; */\n    outline: none;\n  }\n\n  /* move the grid on the image it lies over */\n  .grid {\n    top: 0;\n    left: 0;\n    position: absolute;\n  }\n\n  select {\n    display: inline;\n  }\n\n  div.clearFloat {\n    clear: both;\n  }\n\n  .attentionMaps {\n    width: 100%;\n  }\n\n  .preload img {\n    opacity: 0;\n    position: absolute;\n    width: 0;\n    height: 0;\n  }\n\n  .attentionTypeSelectBox {\n    width: 40%;\n    border: 1px solid grey;\n    /* outline: 2px solid white; */\n    padding: .5em .8em;\n    margin-right: 1em;\n    margin-bottom: .5em;\n    border-radius: .5em;\n    float: left;\n    user-select: none;\n  }\n\n  .attentionTypeSelectBox:last-child {\n    margin-right: 0;\n  }\n\n  .attentionTypeSelectBox.selected {\n    box-shadow: 0 0 5px #2980b9;\n  }\n\n  .attentionTypeSelectBox h4 {\n    margin-top: 0;\n    font-variant: small-caps;\n    /* font-weight: normal; */\n  }\n\n  .imagesContainer {\n    margin-left: 3%;\n  }\n</style>\n\n<main>\n  <h1>Visualization of Self-Attention Maps in Vision</h1>\n\n  <p>\n  This interactive webpage illustrates the findings of our paper <a href=\"https://openreview.net/pdf?id=HJlnC1rKPB\">On the Relationship between Self-Attention and Convolutional Layers</a> published at ICLR 2020.\n  We prove that a Self-Attention layer can express any convolution (under basic conditions met in practice) by attending on (groups of) pixels at fixed shift of the query pixel.\n  This expressivity result is somehow matched in practice for some heads that ignore the content and compute a peak attention probability at a fixed shift (up to a symmetry).\n  </p>\n\n  <p>\n  This page displays interactive attention maps computed by a 6-layer self-attention model trained to classify CIFAR-10 images.\n  You can consult our <a href=\"http://jbcordonnier.com/posts/attention-cnn/\">blog post</a> for a gentle introduction to our paper.\n  The code is available on  <a href=\"https://github.com/epfml/attention-cnn\">Github</a>, the experimental settings is detailed in the paper.\n  </p>\n\n  <h4>Select attention type:</h4>\n  <div class=\"attentionTypeSelect\">\n    <div class=\"attentionTypeSelectBox\" on:click={() => { useAttentionContent = true; }} class:selected={useAttentionContent}>\n      <h4>Standard self-attention</h4>\n      Use both relative positional encoding and input image content to compute the attention scores.\n    </div>\n    <div class=\"attentionTypeSelectBox\" on:click={() => { useAttentionContent = false; }} class:selected={!useAttentionContent}>\n      <h4>Position-only self-attention</h4>\n      Discard the pixel values of the input image to compute the attention scores.\n      Attention relies only on relative positions.\n    </div>\n  </div>\n\n  <div class=\"clearFloat\"></div>\n\n  <br />\n  <b>Display values:</b>\n  {#if useAttentionContent}\n    <select bind:value={selectedContentAttentionType}>\n      {#each contentAttentionTypes as [display, value]}\n        <option type=\"radio\" {value}>{display}</option>\n      {/each}\n    </select>\n  {:else}\n    <select bind:value={selectedPositionAttentionType}>\n      {#each positionAttentionDisplays as [display, value]}\n        <option type=\"radio\" {value}>{display}</option>\n      {/each}\n    </select>\n  {/if}\n  <b>with softmax</b>\n  <input type=checkbox bind:checked={withSoftmax}>\n\n  <h4>Select image and query pixel:</h4>\n\n  <div class=\"imagesContainer\">\n    {#each useAttentionContent ? ['batch', 2, 3, 19, 56] : [\"position\"] as index}\n      <div class=\"sampleImage\" class:selected={index === selectedImage}>\n        <img\n          src={'./cifar10-test-images/image_' + index + '.jpg'}\n          alt=\"\"\n          width={numberColumns * squareSize}\n          on:click={() => onSelectImage(index)} />\n        {#if selectedImage == index}\n          <div class=\"grid\">\n            <Grid\n              columns={numberColumns}\n              rows={numberColumns}\n              {selectedColumn}\n              {selectedRow}\n              {onChangeRowColumn}\n              size={squareSize}\n              class=\"grid\" />\n          </div>\n        {/if}\n      </div>\n    {/each}\n  </div>\n\n  <div class=\"clearFloat\"></div>\n\n  <h4>Visualize values per layer and head</h4>\n\n  <img src={filename} alt=\"\" class=\"attentionMaps\" />\n\n  <div class=\"preload\">\n    {#each _.range(numberColumns) as col}\n      {#each _.range(numberColumns) as row}\n        <img src={filenameAt(col, row)} alt=\"preload\"/>\n      {/each}\n    {/each}\n  </div>\n\n</main>\n"
  ],
  "names": [],
  "mappings": "AA8DE,YAAY,cAAC,CAAC,AACZ,YAAY,CAAE,IAAI,CAClB,aAAa,CAAE,GAAG,CAClB,QAAQ,CAAE,QAAQ,CAClB,KAAK,CAAE,IAAI,CAEX,MAAM,CAAE,IAAI,AACd,CAAC,AAED,SAAS,cAAC,CAAC,AACT,UAAU,CAAE,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAE3B,OAAO,CAAE,IAAI,AACf,CAAC,AAGD,KAAK,cAAC,CAAC,AACL,GAAG,CAAE,CAAC,CACN,IAAI,CAAE,CAAC,CACP,QAAQ,CAAE,QAAQ,AACpB,CAAC,AAED,MAAM,cAAC,CAAC,AACN,OAAO,CAAE,MAAM,AACjB,CAAC,AAED,GAAG,WAAW,cAAC,CAAC,AACd,KAAK,CAAE,IAAI,AACb,CAAC,AAED,cAAc,cAAC,CAAC,AACd,KAAK,CAAE,IAAI,AACb,CAAC,AAED,sBAAQ,CAAC,GAAG,cAAC,CAAC,AACZ,OAAO,CAAE,CAAC,CACV,QAAQ,CAAE,QAAQ,CAClB,KAAK,CAAE,CAAC,CACR,MAAM,CAAE,CAAC,AACX,CAAC,AAED,uBAAuB,cAAC,CAAC,AACvB,KAAK,CAAE,GAAG,CACV,MAAM,CAAE,GAAG,CAAC,KAAK,CAAC,IAAI,CAEtB,OAAO,CAAE,IAAI,CAAC,IAAI,CAClB,YAAY,CAAE,GAAG,CACjB,aAAa,CAAE,IAAI,CACnB,aAAa,CAAE,IAAI,CACnB,KAAK,CAAE,IAAI,CACX,WAAW,CAAE,IAAI,AACnB,CAAC,AAED,qCAAuB,WAAW,AAAC,CAAC,AAClC,YAAY,CAAE,CAAC,AACjB,CAAC,AAED,uBAAuB,SAAS,cAAC,CAAC,AAChC,UAAU,CAAE,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,AAC7B,CAAC,AAED,qCAAuB,CAAC,EAAE,cAAC,CAAC,AAC1B,UAAU,CAAE,CAAC,CACb,YAAY,CAAE,UAAU,AAE1B,CAAC,AAED,gBAAgB,cAAC,CAAC,AAChB,WAAW,CAAE,EAAE,AACjB,CAAC"
}