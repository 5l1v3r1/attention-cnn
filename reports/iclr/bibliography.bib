
@article{belloAttentionAugmentedConvolutional2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1904.09925},
  primaryClass = {cs},
  title = {Attention {{Augmented Convolutional Networks}}},
  abstract = {Convolutional networks have been the paradigm of choice in many computer vision applications. The convolution operation however has a significant weakness in that it only operates on a local neighborhood, thus missing global information. Self-attention, on the other hand, has emerged as a recent advance to capture long range interactions, but has mostly been applied to sequence modeling and generative modeling tasks. In this paper, we consider the use of self-attention for discriminative visual tasks as an alternative to convolutions. We introduce a novel two-dimensional relative self-attention mechanism that proves competitive in replacing convolutions as a stand-alone computational primitive for image classification. We find in control experiments that the best results are obtained when combining both convolutions and self-attention. We therefore propose to augment convolutional operators with this self-attention mechanism by concatenating convolutional feature maps with a set of feature maps produced via self-attention. Extensive experiments show that Attention Augmentation leads to consistent improvements in image classification on ImageNet and object detection on COCO across many different models and scales, including ResNets and a state-of-the art mobile constrained network, while keeping the number of parameters similar. In particular, our method achieves a \$1.3\textbackslash\%\$ top-1 accuracy improvement on ImageNet classification over a ResNet50 baseline and outperforms other attention mechanisms for images such as Squeeze-and-Excitation. It also achieves an improvement of 1.4 mAP in COCO Object Detection on top of a RetinaNet baseline.},
  journal = {arXiv:1904.09925 [cs]},
  author = {Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V.},
  month = apr,
  year = {2019},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/jb/Documents/Zotero/storage/5Y9ZQTSA/Bello et al. - 2019 - Attention Augmented Convolutional Networks.pdf;/Users/jb/Documents/Zotero/storage/ZXTGZRIR/1904.html}
}


@article{dai2019transformerxl,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1901.02860},
  title = {Transformer-{{XL}}: {{Attentive Language Models Beyond}} a {{Fixed}}-{{Length Context}}},
  volume = {abs/1901.02860},
  journal = {CoRR},
  author = {Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime G. and Le, Quoc V. and Salakhutdinov, Ruslan},
  year = {2019},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1901-02860},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
